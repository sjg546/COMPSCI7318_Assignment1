
@incollection{bandyopadhyay_statistical_2011,
  address   = {Amsterdam},
  series    = {Handbook of the {Philosophy} of {Science}},
  title     = {Statistical {Learning} {Theory} as a {Framework} for the {Philosophy} of {Induction}},
  volume    = {7},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780444518620500277},
  abstract  = {Publisher Summary Statistical Learning Theory is the basic theory behind contemporary machine learning and pattern recognition. It suggests that the theory provides an excellent framework for the philosophy of induction. There are various paradigmatic approaches to specifying the problem of induction. It assumes one has an initial known subjective probability distribution satisfying certain more or less weak conditions along with a method for updating one's probabilities, e.g. by conditionalization, and proves theorems about the results of such a method. Statistical learning theory represents another paradigm which assumes there is an unknown objective probability distribution that characterizes the data and the new cases about which inferences are to be made, the goal being to do as well as possible in characterizing the new cases in terms of that unknown objective probability distribution. The basic theory attempts to specify what can be proved about various methods for using data to reach conclusions about new cases.},
  booktitle = {Philosophy of {Statistics}},
  publisher = {North-Holland},
  author    = {Harman, Gilbert and Kulkarni, Sanjeev},
  editor    = {Bandyopadhyay, Prasanta S. and Forster, Malcolm R.},
  year      = {2011},
  doi       = {https://doi.org/10.1016/B978-0-444-51862-0.50027-7},
  note      = {ISSN: 18789846},
  pages     = {833--847}
}

@misc{kagglePimaIndians,
  author       = {Kaggle},
  title        = {Pima Indians Diabetes Database --- kaggle.com},
  howpublished = {\url{https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database}},
  year         = {},
  note         = {[Accessed 10-09-2024]}
}

@article{gholamy_why_nodate,
  title    = {Why 70/30 or 80/20 {Relation} {Between} {Training} and {Testing} {Sets}: {A} {Pedagogical} {Explanation}},
  abstract = {When learning a dependence from data, to avoid overﬁtting, it is important to divide the data into the training set and the testing set. We ﬁrst train our model on the training set, and then we use the data from the testing set to gauge the accuracy of the resulting model. Empirical studies show that the best results are obtained if we use 20-30\% of the data for testing, and the remaining 70-80\% of the data for training. In this paper, we provide a possible explanation for this empirical result.},
  language = {en},
  author   = {Gholamy, Afshin and Kreinovich, Vladik and Kosheleva, Olga},
  file     = {https://scholarworks.utep.edu/cgi/viewcontent.cgi?article=2202&context=cs_techrep}
}

@misc{cornellProfessorsPerceptron,
  author       = {},
  title        = {{P}rofessor’s perceptron paved the way for {A}{I} – 60 years too soon | {C}ornell {C}hronicle --- news.cornell.edu},
  howpublished = {\url{https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon}},
  year         = {},
  note         = {[Accessed 14-09-2024]}
}